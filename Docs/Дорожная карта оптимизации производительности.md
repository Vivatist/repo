# Дорожная карта оптимизации производительности NovaVPN

> Дата создания: 14.02.2026
> Последнее обновление: 14.02.2026
> Статус: этапы 0–4 завершены

---

## Принципы

Все оптимизации подчиняются приоритетам проекта:
1. **Маскировка** — ни одно изменение не должно ухудшать stealth
2. **Производительность** — цель этой дорожной карты
3. **Безопасность** — шифрование неприкосновенно (оно же часть маскировки)

**Шифрование нельзя убрать/ослабить** — ChaCha20 создаёт high-entropy данные внутри TLS record, что критично для маскировки. Без шифрования DPI обнаружит structured IPv4 headers по паттерну энтропии.

---

## Профиль нагрузки (на 1 пакет, 1400 байт)

| Операция | Время | Доля CPU |
|----------|-------|----------|
| ChaCha20 init + XOR | ~400 нс | 4% |
| UDP syscall (read/write) | ~2000 нс | 40% |
| TUN syscall (read/write) | ~2000 нс | 40% |
| Session lookup (RLock) | ~100 нс | 1% |
| Прочее | ~1500 нс | 15% |

**Вывод:** 80% времени — системные вызовы (syscalls). Оптимизировать надо I/O.

---

## Уже выполненные оптимизации (фаза 0)

- [x] `ExtractDstIPKey` — zero-alloc извлечение dst IP как `[4]byte`
- [x] `GetSessionByIPKey` — zero-alloc lookup сессии по IP-ключу
- [x] `tunReadLoop` — интеграция zero-alloc lookup
- [x] `randomKeepaliveInterval` — убраны allocations `big.Int`
- [x] `randomCheckInterval` (клиент) — убраны `big.Int`
- [x] `keepaliveLoop` (клиент) — `time.After` → `time.Timer` (корректная очистка)
- [x] `monitorLoop` (клиент) — `time.After` → `time.Timer`

---

## Этап 1: Batch UDP отправка — sendmmsg (сервер) ✅

**Файлы:** `vpn-server/internal/server/server.go`, `vpn-server/internal/server/batch_linux.go`

**Проблема:** `tunReadLoop` отправляет пакеты по одному через `WriteToUDP` — 1 syscall / пакет.

**Решение:** Кольцевой буфер `batchSender` + `sendmmsg` — до 64 пакетов за 1 syscall.

**Реализовано:**
- `batchSender` — ring buffer с пре-аллоцированными буферами (64 слота)
- Flush goroutine с таймером 100 мкс + немедленный flush при заполнении
- `sendToClientBatch` — шифрование прямо в batch-буфер (zero-copy)
- Fallback на `WriteToUDP` если `getUDPSocketFd` не удался

**Влияние на маскировку:** нулевое (wire format не меняется).

**Статус:** ✅ завершён

---

## Этап 2: Batch UDP приём — recvmmsg (сервер) ✅

**Файлы:** `vpn-server/internal/server/server.go`, `vpn-server/internal/server/batch_linux.go`

**Проблема:** `udpReadLoop` читает по 1 пакету через `ReadFromUDP` — 1 syscall / пакет.

**Решение:** `recvmmsg` + `batchReceiver` читает до 64 пакетов за 1 syscall.

**Реализовано:**
- `batchReceiver` — пре-аллоцированные буферы, iovec, sockaddr для 64 пакетов
- `recvmmsg` syscall с `MSG_WAITFORONE` (возврат после первого пакета)
- `processUDPPacket` — извлечённый метод обработки одного пакета (batch + fallback)
- Fallback на `ReadFromUDP` если batch receiver не инициализирован

**Влияние на маскировку:** нулевое.

**Статус:** ✅ завершён

---

## Этап 3: Увеличение UDP буферов (сервер) ✅

**Файлы:** `vpn-server/internal/server/server.go`

**Проблема:** Стандартные буферы UDP-сокета (4 МБ) переполняются при burst'ах.

**Решение:** Fallback-стратегия: 16 МБ → 8 МБ → 4 МБ с логированием.

**Реализовано:**
- `tuneSocketBuffers()` — метод с fallback через 3 уровня (16/8/4 МБ)
- Логирование реально установленного размера буфера

**Влияние на маскировку:** нулевое.

**Статус:** ✅ завершён

---

## Этап 4: LRU-1 session cache (сервер) ✅

**Файлы:** `vpn-server/internal/server/session.go`, `vpn-server/internal/server/server.go`

**Проблема:** `GetSessionByID` и `GetSessionByIPKey` берут `RWMutex.RLock` на каждый пакет.

**Решение:** LRU-1 кеш вместо `sync.Map` (sync.Map создаёт interface boxing = аллокация на каждый пакет).

**Реализовано:**
- `sessionCache` — кеш последней сессии по SessionID для `udpReadLoop` (1 горутина)
- `ipSessionCache` — кеш последней сессии по VPN IP для `tunReadLoop` (1 горутина)
- При cache hit — нулевая стоимость (без RLock, без map lookup)
- Корректность: stale session обнаруживается через `IsActive()` (atomic state)
- Монотонный sessionID гарантирует отсутствие ID reuse

**Ожидаемый эффект:** устранение RLock на hot path для single-client (100% hit rate), высокий hit rate для multi-client (пакеты кластеризованы по сессиям).

**Влияние на маскировку:** нулевое.

**Статус:** ✅ завершён

---

## Этап 5: GRO/GSO для TUN (сервер, экспериментальный)

**Файлы:** `vpn-server/internal/tun/tun_linux.go`

**Проблема:** Каждый `Read`/`Write` на TUN — 1 пакет = 1 syscall. Linux 5.16+ поддерживает virtio GRO/GSO для TUN/TAP — до 64K данных за 1 syscall.

**Решение:** Активировать `IFF_VNET_HDR` + virtio header при создании TUN, реализовать batch read/write.

**Ожидаемый эффект:** 2-5x снижение TUN syscall overhead (вторые 40% нагрузки).

**Влияние на маскировку:** нулевое.

**Статус:** ⬜ не начат (требует Linux 5.16+, экспериментальный)

---

## Этап 6: MTU tuning + фрагментация (сервер + клиент)

**Файлы:** `vpn-server/config/config.go`, документация

**Проблема:** MTU = 1400 → на проводе 1400 + 14 (data overhead) + 8 (UDP) + 20 (IP) = **1442 байт**. Если ISP-путь имеет MTU < 1442 (PPPoE = 1492 OK, некоторые LTE/tunnels = 1440), каждый VPN-пакет фрагментируется → двойной syscall overhead + потери.

**Решение:**
1. Снизить MTU до 1380 по умолчанию (1380+14+8+20 = 1422 — безопасно даже для PPPoE)
2. Добавить конфигурируемый параметр `mtu_discovery: auto|manual`
3. Документировать рекомендации

**Ожидаемый эффект:** устранение фрагментации = x2 выигрыш для пользователей с узким MTU.

**Влияние на маскировку:** нулевое.

**Статус:** ⬜ не начат

---

## Этап 7: Оптимизации клиента (Windows)

**Файлы:** `vpn-client-windows/internal/infrastructure/vpn/client.go`, `crypto/session.go`

**Проблема:** Мелкие аллокации на hot path клиента.

**Решение:**
1. `udpReadLoop` — увеличить буфер чтения с 2048 до MTU+DataOverhead+100
2. `DecryptWithCounter` — проверить reuse буфера `recvBuf` (уже сделано, OK)
3. `WinTUNDevice.Read` — WaitForSingleObject таймаут 100мс → 1000мс (меньше wakeup'ов в idle)

**Ожидаемый эффект:** незначительный (~5%), но снижает CPU usage в idle.

**Влияние на маскировку:** нулевое.

**Статус:** ⬜ не начат

---

## Порядок реализации

```
Этап 0 ✅  Zero-alloc hot path
  │
  ▼
Этап 1 ✅  sendmmsg batch sender
  │
  ▼
Этап 2 ✅  recvmmsg batch receiver + processUDPPacket
  │
  ▼
Этап 3 ✅  UDP socket buffer tuning (16/8/4 МБ fallback)
  │
  ▼
Этап 4 ✅  LRU-1 session cache (sessionCache + ipSessionCache)
  │
  ▼  
Этап 5 ⬜  GRO/GSO TUN (экспериментальный, высокий эффект)
  │
  ▼
Этап 6 ⬜  MTU tuning (конфигурация, документация)
  │
  ▼
Этап 7 ⬜  Клиентские мелочи (низкий приоритет)
```

---

## Метрики успеха

| Метрика | Текущее | Цель |
|---------|---------|------|
| Syscalls на 10K pps (send) | 10,000 | < 500 |
| Syscalls на 10K pps (recv) | 10,000 | < 500 |
| Аллокации на data-пакет | 0-1 | 0 |
| RLock contention при 10 клиентах | заметная | нулевая |
| Throughput (1 клиент) | ~300-500 Mbps* | ~800+ Mbps |
| Throughput (10 клиентов) | ~200-300 Mbps* | ~600+ Mbps |

*оценка, зависит от сервера
